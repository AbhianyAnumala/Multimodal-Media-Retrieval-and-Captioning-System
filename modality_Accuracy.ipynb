{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKbw8KIPrGKqdd7scgORAl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhianyAnumala/Multimodal-Media-Retrieval-and-Captioning-System/blob/feature_brnach/modality_Accuracy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#WEEK2"
      ],
      "metadata": {
        "id": "1OxA9HjDVeGh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load embeddings\n",
        "\n",
        "### Subtask:\n",
        "Load all the saved image and text embeddings into memory. You might want to organize them in a way that allows for easy lookup, e.g., dictionaries mapping image names to embeddings."
      ],
      "metadata": {
        "id": "y6RN1QG1cftp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcgnTY2OdESQ",
        "outputId": "b89118c7-ac9a-44df-d0f0-da469641ab7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import cosine_similarity\n",
        "# Check if CUDA is available and set the device accordingly\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "oVU2cX32dTHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "90Gz6Qr4VaCn",
        "outputId": "90c43846-34c3-409e-aa20-a5e3f5d6e3f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading image embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 8091 image embeddings.\n",
            "Loading text embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n",
            "<ipython-input-6-bcf4c423fd7f>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embedding = torch.load(filepath)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 8091 text embeddings.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "# Define the directories where embeddings are saved\n",
        "image_embeddings_dir = \"/content/drive/MyDrive/AIML_Lab/Capstone_Project/clip_image_embeddings\"\n",
        "text_embeddings_dir = \"/content/drive/MyDrive/AIML_Lab/Capstone_Project/clip_text_embeddings\"\n",
        "\n",
        "# Create dictionaries to store embeddings\n",
        "image_embeddings_dict = {}\n",
        "text_embeddings_dict = {}\n",
        "\n",
        "# Load image embeddings\n",
        "print(\"Loading image embeddings...\")\n",
        "for filename in os.listdir(image_embeddings_dir):\n",
        "    if filename.endswith(\".pt\"):\n",
        "        image_name = os.path.splitext(filename)[0]\n",
        "        filepath = os.path.join(image_embeddings_dir, filename)\n",
        "        try:\n",
        "            embedding = torch.load(filepath)\n",
        "            image_embeddings_dict[image_name] = embedding\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image embedding {filename}: {e}\")\n",
        "\n",
        "print(f\"Loaded {len(image_embeddings_dict)} image embeddings.\")\n",
        "\n",
        "# Load text embeddings\n",
        "print(\"Loading text embeddings...\")\n",
        "for filename in os.listdir(text_embeddings_dir):\n",
        "    if filename.endswith(\".pt\"):\n",
        "        image_name = os.path.splitext(filename)[0]\n",
        "        filepath = os.path.join(text_embeddings_dir, filename)\n",
        "        try:\n",
        "            embedding = torch.load(filepath)\n",
        "            text_embeddings_dict[image_name] = embedding\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading text embeddings {filename}: {e}\")\n",
        "\n",
        "print(f\"Loaded {len(text_embeddings_dict)} text embeddings.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Image-to-text Accuracy**"
      ],
      "metadata": {
        "id": "ZmdsN2lL7z9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get top N similare embeddings"
      ],
      "metadata": {
        "id": "N5FYV-4sRspL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_n_text_results_for_image(image_embeddings, text_embeddings_dict, n=5):\n",
        "    similarity_scores = {}\n",
        "    ## compare the given image embedding with all text emdeddings.\n",
        "    # Assuming image_embeddings is a single embedding for the query image\n",
        "    # Reshape query embedding for cosine similarity calculation if it's 1D\n",
        "    if len(image_embeddings.shape) == 1:\n",
        "        query_embedding_reshaped = image_embeddings.unsqueeze(0) # Use unsqueeze for PyTorch tensors\n",
        "    else:\n",
        "        query_embedding_reshaped = image_embeddings\n",
        "\n",
        "\n",
        "    for image_name, embeddings_list in text_embeddings_dict.items():\n",
        "        if embeddings_list is not None and len(embeddings_list) > 0: # Added check for empty list\n",
        "            for index, caption_embedding in enumerate(embeddings_list): # Added enumerate to get index\n",
        "                if caption_embedding is not None: # Added check for None embedding\n",
        "                  # Ensure embeddings are on the same device\n",
        "                  # query_embedding_reshaped is already on 'device' from loading\n",
        "\n",
        "                  # Reshape caption embedding if it's 1D\n",
        "                  if len(caption_embedding.shape) == 1:\n",
        "                      caption_embedding = caption_embedding.unsqueeze(0) # Use unsqueeze for PyTorch tensors\n",
        "\n",
        "\n",
        "                  # Calculate cosine similarity (assuming it returns a tensor)\n",
        "                  score = cosine_similarity(query_embedding_reshaped, caption_embedding, dim=1) # Use dim=1 for batch comparison\n",
        "                  similarity_scores[image_name+\"@\"+str(index)] = score.item() # Store scalar score and use string index\n",
        "        else:\n",
        "            # Handle case where embeddings_list is None or empty for an image\n",
        "            similarity_scores[image_name] = -1 # Or some other indicator\n",
        "\n",
        "    ## sort the scores\n",
        "    sorted_similarity_scores = sorted(similarity_scores.items(), key=lambda item: item[1], reverse=True)\n",
        "    ## get top n results\n",
        "    top_n_results = sorted_similarity_scores[:n] # Use the provided n for top results\n",
        "    return top_n_results"
      ],
      "metadata": {
        "id": "8qfS0-xvIPue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing embeddings from Search with Actual"
      ],
      "metadata": {
        "id": "DUSgI6LgRbSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_with_actual_text(top_n_results, image_name):\n",
        "    for result_key, result_score in top_n_results:\n",
        "      # Split the key to get the image name and caption index of the result\n",
        "      result_image_name, result_caption_index_str = result_key.split(\"@\")\n",
        "      if  result_image_name == image_name:\n",
        "          return 1\n",
        "    return 0 # Return 0 if no correct match is found in the top results"
      ],
      "metadata": {
        "id": "1mnJYLfDOMW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test for one image embeddings"
      ],
      "metadata": {
        "id": "KD9UYNfyRVoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## test for one image embedding from dict\n",
        "image_name_to_get = list(image_embeddings_dict.keys())[0] # Get the first image name as an example\n",
        "mage_embedding = image_embeddings_dict[image_name_to_get]\n",
        "top_n_results = get_top_n_text_results_for_image(mage_embedding,text_embeddings_dict,5)\n",
        "print(top_n_results)\n",
        "vaa = compare_with_actual_text(top_n_results,image_name_to_get)\n",
        "print(vaa)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrH8gJDwLiYA",
        "outputId": "4a78947b-5cce-4bf5-d5cd-5c5f4e1e6edf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('395461421_c586b136de@0', 0.3416922390460968), ('2351479551_e8820a1ff3@4', 0.32637324929237366), ('2891162278_fbf96be4f4@0', 0.3214271366596222), ('395461421_c586b136de@3', 0.3180912435054779), ('427167162_2c99779444@1', 0.3175909221172333)]\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test for all embeddings with different top n results\n",
        "\n"
      ],
      "metadata": {
        "id": "7xNulgSaWqcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming image_embeddings_dict and text_embeddings_dict are loaded\n",
        "# Assuming get_top_n_text_results_for_image and compare_with_actual_text are defined and corrected\n",
        "\n",
        "k = 5 # You can set k to the maximum number of top results you want to check for accuracy\n",
        "\n",
        "top_n_results_dict_image_to_text = {}\n",
        "\n",
        "# Iterate through each image embedding in the dictionary\n",
        "for image_name, image_embedding in list(image_embeddings_dict.items())[:1000]:\n",
        "    # Get the top N text results for the current image embedding\n",
        "    # Using the corrected get_top_n_text_results_for_image function\n",
        "    top_n_results_dict_image_to_text[image_name] = get_top_n_text_results_for_image(image_embedding, text_embeddings_dict, k)\n",
        "\n",
        "accuracy_results = {}\n",
        "\n",
        "print(\"Calculating image-to-text accuracy for different top N values...\")\n",
        "\n",
        "# Iterate through different values of N (from 1 to k)\n",
        "for top_n_accuracy in range(1, k + 1):\n",
        "    correct_matches_count = 0\n",
        "    total_images = len(image_embeddings_dict)\n",
        "    for image_name, top_n_results in top_n_results_dict_image_to_text.items():\n",
        "        # Check if any of the actual text embeddings for this image are in the top N results\n",
        "        # Using the corrected compare_with_actual_text function\n",
        "        # Note: The compare_with_actual_text function returns 1 if a match is found, 0 otherwise.\n",
        "        is_correct_match_found = compare_with_actual_text(top_n_results, image_name)\n",
        "\n",
        "        if is_correct_match_found == 1:\n",
        "            correct_matches_count += 1\n",
        "\n",
        "    # Calculate accuracy for the current top_n_accuracy value\n",
        "    accuracy = correct_matches_count / total_images if total_images > 0 else 0\n",
        "    accuracy_results[top_n_accuracy] = accuracy\n",
        "\n",
        "    print(f\"Accuracy for top {top_n_accuracy} results: {accuracy:.4f}\")\n",
        "\n",
        "# Print all accuracy results\n",
        "print(\"\\nOverall Accuracy Results:\")\n",
        "for n, acc in accuracy_results.items():\n",
        "    print(f\"Top {n}: {acc:.4f}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zZGmxNWUhEuf",
        "outputId": "70137d67-f7cc-4807-f9d4-84061e90e1cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "\n",
            "---\n",
            "Calculating image-to-text accuracy for different top N values...\n",
            "Accuracy for top 1 results: 0.0870\n",
            "Accuracy for top 2 results: 0.0870\n",
            "Accuracy for top 3 results: 0.0870\n",
            "Accuracy for top 4 results: 0.0870\n",
            "Accuracy for top 5 results: 0.0870\n",
            "\n",
            "Overall Accuracy Results:\n",
            "Top 1: 0.0870\n",
            "Top 2: 0.0870\n",
            "Top 3: 0.0870\n",
            "Top 4: 0.0870\n",
            "Top 5: 0.0870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Text-to-Image Accuracy**"
      ],
      "metadata": {
        "id": "IPDpXp8QTXqx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###get top n image results for text"
      ],
      "metadata": {
        "id": "GomfioOyXQVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_n_image_results_for_text(text_embedding, image_embeddings_dict, n=5):\n",
        "    similarity_scores = {}\n",
        "\n",
        "    # Assuming text_embedding is a single embedding for the query text\n",
        "    # Reshape query embedding for cosine similarity calculation if it's 1D\n",
        "    if len(text_embedding.shape) == 1:\n",
        "        query_embedding_reshaped = text_embedding.unsqueeze(0)\n",
        "    else:\n",
        "        query_embedding_reshaped = text_embedding\n",
        "\n",
        "    for image_name, image_embedding in image_embeddings_dict.items():\n",
        "        if image_embedding is not None:\n",
        "\n",
        "            # Reshape image embedding if it's 1D\n",
        "            if len(image_embedding.shape) == 1:\n",
        "                image_embedding = image_embedding.unsqueeze(0)\n",
        "            else:\n",
        "                image_embedding = image_embedding\n",
        "\n",
        "            # Calculate cosine similarity\n",
        "            score = cosine_similarity(query_embedding_reshaped, image_embedding, dim=1)\n",
        "            similarity_scores[image_name] = score.item() # Store scalar score\n",
        "\n",
        "    # Sort the scores\n",
        "    sorted_similarity_scores = sorted(similarity_scores.items(), key=lambda item: item[1], reverse=True)\n",
        "    # Get top n results\n",
        "    top_n_results = sorted_similarity_scores[:n]\n",
        "    return top_n_results"
      ],
      "metadata": {
        "id": "Z03iktSxW9D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Compare with actual image"
      ],
      "metadata": {
        "id": "IpVrF4isXWJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_with_actual_image(top_n_results, actual_image_name):\n",
        "    for result_image_name, result_score in top_n_results:\n",
        "        if result_image_name == actual_image_name:\n",
        "            return 1  # Found the correct image in the top results\n",
        "    return 0  # Return 0 if the correct image is not found"
      ],
      "metadata": {
        "id": "bVqUVBfDW_AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test for all embeddings with different top n results\n"
      ],
      "metadata": {
        "id": "rhb7R7okXgFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 5 # You can set k to the maximum number of top results you want to check for accuracy\n",
        "\n",
        "top_n_results_dict_text_to_image ={}\n",
        "evaluated_embeddings_count = 0 # To track the number of text embeddings we actually process\n",
        "# Iterate through each image and its associated text embeddings\n",
        "for image_name, text_embeddings_list in list(image_embeddings_dict.items())[:100]:\n",
        "  if text_embeddings_list is not None and len(text_embeddings_list) > 0:\n",
        "    # For each text embedding associated with the image\n",
        "    for i, text_embedding in enumerate(text_embeddings_list):\n",
        "      if text_embedding is not None:\n",
        "        # Get the top N image results for the current text embedding\n",
        "        top_n_results_dict_text_to_image[image_name+\"@\"+str(i)] = get_top_n_image_results_for_text(text_embedding, image_embeddings_dict, k)\n",
        "        evaluated_embeddings_count += 1\n",
        "\n",
        "accuracy_results_text_to_image = {}\n",
        "\n",
        "print(\"\\nCalculating text-to-image accuracy for different top N values...\")\n",
        "\n",
        "# To evaluate text-to-image, we need to iterate through each text embedding\n",
        "# and find its corresponding image. The text embeddings are stored per image,\n",
        "# so we can iterate through the text_embeddings_dict.\n",
        "total_text_embeddings = sum(len(embeddings) for embeddings in text_embeddings_dict.values() if embeddings is not None)\n",
        "\n",
        "\n",
        "# Iterate through different values of N (from 1 to k)\n",
        "for top_n_accuracy in range(1, k + 1):\n",
        "    correct_matches_count = 0\n",
        "    for text_name ,top_n_results in top_n_results_dict_text_to_image.items():\n",
        "        # Split the key to get the image name\n",
        "        image_name = text_name.split(\"@\")[0]\n",
        "        # Check if the actual image for this text embedding is in the top N results\n",
        "        is_correct_match_found = compare_with_actual_image(top_n_results, image_name)\n",
        "        if is_correct_match_found == 1:\n",
        "          correct_matches_count += 1\n",
        "\n",
        "    # Calculate accuracy for the current top_n_accuracy value\n",
        "    accuracy = correct_matches_count / evaluated_embeddings_count if evaluated_embeddings_count > 0 else 0\n",
        "    accuracy_results_text_to_image[top_n_accuracy] = accuracy\n",
        "\n",
        "    print(f\"Accuracy for top {top_n_accuracy} results (Text-to-Image): {accuracy:.4f}\")\n",
        "\n",
        "# Print all accuracy results for text-to-image\n",
        "print(\"\\nOverall Accuracy Results (Text-to-Image):\")\n",
        "for n, acc in accuracy_results_text_to_image.items():\n",
        "    print(f\"Top {n}: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "SQn33Y8iTjtX",
        "outputId": "f27a4a32-8228-4099-f1db-3f2652725ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-cb8c554e5321>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtext_embedding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Get the top N image results for the current text embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtop_n_results_dict_text_to_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"@\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_top_n_image_results_for_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_embeddings_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mevaluated_embeddings_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-69225015534d>\u001b[0m in \u001b[0;36mget_top_n_image_results_for_text\u001b[0;34m(text_embedding, image_embeddings_dict, n)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# Calculate cosine similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_embedding_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0msimilarity_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Store scalar score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Text-to-Text Accuracy**\n"
      ],
      "metadata": {
        "id": "WyadCsZXVDG0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Get top n text results for text"
      ],
      "metadata": {
        "id": "MCwcj8eEXo74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To evaluate text-to-text, we compare a given text embedding with all other text embeddings.\n",
        "# We need to find the most similar text embeddings and check if they belong to the same image\n",
        "# or are different captions for the same image.\n",
        "\n",
        "def get_top_n_text_results_for_text(query_text_embedding, text_embeddings_dict, query_image_name, query_caption_index, n=5):\n",
        "    \"\"\"\n",
        "    Finds the top N most similar text embeddings for a given query text embedding,\n",
        "    excluding the query embedding itself.\n",
        "\n",
        "    Args:\n",
        "        query_text_embedding (torch.Tensor): The embedding of the text we are querying with.\n",
        "        text_embeddings_dict (dict): Dictionary mapping image names to lists of text embeddings.\n",
        "        query_image_name (str): The name of the image the query text embedding belongs to.\n",
        "        query_caption_index (int): The index of the query text embedding within its image's list.\n",
        "        n (int): The number of top results to return.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of tuples (result_key, similarity_score) for the top N most similar text embeddings.\n",
        "    \"\"\"\n",
        "    similarity_scores = {}\n",
        "\n",
        "    # Reshape query embedding for cosine similarity calculation if it's 1D\n",
        "    if len(query_text_embedding.shape) == 1:\n",
        "        query_embedding_reshaped = query_text_embedding.unsqueeze(0)\n",
        "    else:\n",
        "        query_embedding_reshaped = query_text_embedding\n",
        "\n",
        "    # Iterate through all text embeddings\n",
        "    for image_name, text_embeddings_list in text_embeddings_dict.items():\n",
        "        if text_embeddings_list is not None:\n",
        "            for index, text_embedding in enumerate(text_embeddings_list):\n",
        "                if text_embedding is not None:\n",
        "                    # Create a unique key for each text embedding (image_name@caption_index)\n",
        "                    current_embedding_key = f\"{image_name}@{index}\"\n",
        "\n",
        "                    # Skip the query embedding itself\n",
        "                    if image_name == query_image_name and index == query_caption_index:\n",
        "                        continue\n",
        "\n",
        "                    # Reshape current embedding if it's 1D\n",
        "                    if len(current_embedding_reshaped.shape) == 1:\n",
        "                        current_embedding_reshaped = text_embedding.unsqueeze(0)\n",
        "                    else:\n",
        "                        current_embedding_reshaped = text_embedding\n",
        "\n",
        "                    # Calculate cosine similarity\n",
        "                    score = cosine_similarity(query_embedding_reshaped, current_embedding_reshaped, dim=1)\n",
        "                    similarity_scores[current_embedding_key] = score.item()\n",
        "\n",
        "    # Sort the scores\n",
        "    sorted_similarity_scores = sorted(similarity_scores.items(), key=lambda item: item[1], reverse=True)\n",
        "    # Get top n results\n",
        "    top_n_results = sorted_similarity_scores[:n]\n",
        "    return top_n_results\n"
      ],
      "metadata": {
        "id": "JYZhERiOXD05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Compare with actual text to text"
      ],
      "metadata": {
        "id": "cvsPbAlWXvoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_with_actual_text_to_text(top_n_results, query_image_name):\n",
        "    \"\"\"\n",
        "    Checks if any of the top N most similar text embeddings belong to the same image\n",
        "    as the query text embedding.\n",
        "\n",
        "    Args:\n",
        "        top_n_results (list): A list of tuples (result_key, similarity_score) for the top N results.\n",
        "        query_image_name (str): The name of the image the query text embedding belongs to.\n",
        "\n",
        "    Returns:\n",
        "        int: 1 if at least one of the top results belongs to the same image, 0 otherwise.\n",
        "    \"\"\"\n",
        "    for result_key, result_score in top_n_results:\n",
        "        try:\n",
        "            # Split the key to get the image name\n",
        "            result_image_name, result_caption_index_str = result_key.split(\"@\")\n",
        "\n",
        "            # Check if the result image name matches the query image name\n",
        "            if result_image_name == query_image_name:\n",
        "                return 1  # Found a text embedding from the same image in the top results\n",
        "        except ValueError as e:\n",
        "             # Handle cases where result key format is invalid\n",
        "             print(f\"Error processing result key {result_key}: {e}\")\n",
        "             pass # Skip this result if there's an error\n",
        "\n",
        "    return 0  # Return 0 if no text embedding from the same image is found in the top results"
      ],
      "metadata": {
        "id": "kj0evXvwXJGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test for all embeddings with different top n results\n"
      ],
      "metadata": {
        "id": "EhSAmJ0_X4lK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 5 # You can set k to the maximum number of top results you want to check for accuracy\n",
        "\n",
        "top_n_results_text_to_text ={}\n",
        "evaluated_embeddings_count = 0 # To track the number of text embeddings we actually process\n",
        "# Iterate through each image and its associated text embeddings\n",
        "for image_name, text_embeddings_list in text_embeddings_dict.items():\n",
        "  if text_embeddings_list is not None and len(text_embeddings_list) > 0:\n",
        "    # For each text embedding associated with the image\n",
        "    for caption_index, text_embedding in enumerate(text_embeddings_list):\n",
        "      if text_embedding is not None:\n",
        "        evaluated_embeddings_count += 1\n",
        "        # Get the top N text results for the current text embedding\n",
        "        top_n_results_text_to_text[image_name +\"@\"+str(caption_index)] = get_top_n_text_results_for_text(text_embedding, text_embeddings_dict, image_name, caption_index, top_n_accuracy)\n",
        "\n",
        "\n",
        "accuracy_results_text_to_text = {}\n",
        "\n",
        "print(\"\\nCalculating text-to-text accuracy for different top N values...\")\n",
        "\n",
        "# To evaluate text-to-text, we iterate through each individual text embedding\n",
        "total_text_embeddings = sum(len(embeddings) for embeddings in text_embeddings_dict.values() if embeddings is not None)\n",
        "\n",
        "# Iterate through different values of N (from 1 to k)\n",
        "for top_n_accuracy in range(1, k + 1):\n",
        "    correct_matches_count = 0\n",
        "    for text_name ,top_n_results in top_n_results_text_to_text.items():\n",
        "        # Split the key to get the image name\n",
        "        image_name = text_name.split(\"@\")[0]\n",
        "        # Check if any of the top N results belong to the same image as the query text\n",
        "        is_correct_match_found = compare_with_actual_text_to_text(top_n_results, image_name)\n",
        "        if is_correct_match_found == 1:\n",
        "          correct_matches_count += 1\n",
        "\n",
        "    # Calculate accuracy for the current top_n_accuracy value\n",
        "    accuracy = correct_matches_count / evaluated_embeddings_count if evaluated_embeddings_count > 0 else 0\n",
        "    accuracy_results_text_to_text[top_n_accuracy] = accuracy\n",
        "\n",
        "    print(f\"Accuracy for top {top_n_accuracy} results (Text-to-Text): {accuracy:.4f}\")\n",
        "\n",
        "# Print all accuracy results for text-to-text\n",
        "print(\"\\nOverall Accuracy Results (Text-to-Text):\")\n",
        "for n, acc in accuracy_results_text_to_text.items():\n",
        "    print(f\"Top {n}: {acc:.4f}\")"
      ],
      "metadata": {
        "id": "zIVq_RC-Uyxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: get precion matrix for image and text embeding dict\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame to store the accuracy results\n",
        "# Combine the results from all three evaluation tasks\n",
        "all_accuracy_results = {\n",
        "    'Image-to-Text': accuracy_results,\n",
        "    'Text-to-Image': accuracy_results_text_to_image,\n",
        "    'Text-to-Text': accuracy_results_text_to_text\n",
        "}\n",
        "\n",
        "precision_matrix = pd.DataFrame(all_accuracy_results).T\n",
        "\n",
        "# Rename columns for clarity (Top 1, Top 2, etc.)\n",
        "precision_matrix.columns = [f'Top {col}' for col in precision_matrix.columns]\n",
        "\n",
        "print(\"\\nPrecision Matrix (Accuracy at different Top N values):\")\n",
        "precision_matrix"
      ],
      "metadata": {
        "id": "FnUonjEOxZYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0617cb12",
        "outputId": "a4de9192-31f0-4237-b94d-fd85bb495297"
      },
      "source": [
        "import os\n",
        "\n",
        "directory_path = \"/content/drive/MyDrive/AIML_Lab/Capstone_Project/clip_text_embeddings_8k/text_embeddings\"\n",
        "\n",
        "# Check if the directory exists\n",
        "if os.path.exists(directory_path):\n",
        "    # List all entries in the directory\n",
        "    entries = os.listdir(directory_path)\n",
        "\n",
        "    # Count only files (excluding directories)\n",
        "    file_count = sum(os.path.isfile(os.path.join(directory_path, entry)) for entry in entries)\n",
        "\n",
        "    print(f\"Number of files in '{directory_path}': {file_count}\")\n",
        "else:\n",
        "    print(f\"Directory not found: '{directory_path}'\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files in '/content/drive/MyDrive/AIML_Lab/Capstone_Project/clip_text_embeddings_8k/text_embeddings': 40455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: so we have 3 types of retrieval imagetotext, texttoimage, texttotext. so will the quantitative results, retrieal scores comparision.\n",
        "# code from start consider u have image and text emdeddings\n",
        "\n",
        "# Print the precision matrix\n",
        "precision_matrix"
      ],
      "metadata": {
        "id": "jS1gG3kUzmrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: draw a graph\n",
        "# x axix 1,2,34\n",
        "# yaxis_1 3.35,1.17,0.673,0.459\n",
        "# yaxis_2 2.52,2.44,2.54,2.62\n",
        "# x - label Epoch, y label train_loss, valid_loss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "epochs = [1, 2, 3, 4]\n",
        "train_losses = [4.25, 2.87, 1.673, 0.859]\n",
        "valid_losses = [2.32, 2.54, 2.84, 3.42]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, train_losses, marker='o', label='Train Loss')\n",
        "plt.plot(epochs, valid_losses, marker='o', label='Valid Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss per Epoch for 30k Dataset')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tO1Kun2U60LK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}